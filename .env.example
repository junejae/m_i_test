# MIG is created only on physical GPU 1.
# GPU 0 is currently occupied and excluded from this stack.
MIG_TARGET_GPU_INDEX=1

# Set these after running: nvidia-smi -L
MIG_UUID_1=MIG-REPLACE-WITH-UUID-1
MIG_UUID_2=MIG-REPLACE-WITH-UUID-2
MIG_UUID_3=MIG-REPLACE-WITH-UUID-3
MIG_UUID_4=MIG-REPLACE-WITH-UUID-4
MIG_UUID_5=MIG-REPLACE-WITH-UUID-5

# vLLM settings
MODEL_1=google/gemma-3-4b-it
MODEL_2=Qwen/Qwen3-VL-8B-Instruct
MODEL_3=dragonkue/BGE-m3-ko
MODEL_4=Dongjin-kr/ko-reranker
MODEL_5=openai/whisper-large-v3
SERVED_MODEL_NAME_1=gemma3-4b-it
SERVED_MODEL_NAME_2=qwen3-vl-8b-instruct
SERVED_MODEL_NAME_3=bge-m3-ko
SERVED_MODEL_NAME_4=ko-reranker
SERVED_MODEL_NAME_5=whisper-large-v3
DTYPE_1=bfloat16
DTYPE_2=bfloat16
DTYPE_3=bfloat16
DTYPE_4=bfloat16
DTYPE_5=bfloat16
GPU_MEMORY_UTILIZATION_1=0.9
GPU_MEMORY_UTILIZATION_2=0.9
GPU_MEMORY_UTILIZATION_3=0.9
GPU_MEMORY_UTILIZATION_4=0.9
GPU_MEMORY_UTILIZATION_5=0.9
MAX_MODEL_LEN_1=1024
MAX_MODEL_LEN_2=768
MAX_MODEL_LEN_3=512
MAX_MODEL_LEN_4=512
MAX_MODEL_LEN_5=2048
MAX_NUM_SEQS_1=1
MAX_NUM_SEQS_2=1
MAX_NUM_SEQS_3=4
MAX_NUM_SEQS_4=4
MAX_NUM_SEQS_5=1
MAX_NUM_BATCHED_TOKENS_1=512
MAX_NUM_BATCHED_TOKENS_2=256
MAX_NUM_BATCHED_TOKENS_3=512
MAX_NUM_BATCHED_TOKENS_4=512
MAX_NUM_BATCHED_TOKENS_5=2048
MM_IMAGE_LIMIT_2=1
MM_VIDEO_LIMIT_2=0
VLLM_EXTRA_ARGS_1=--swap-space 8 --enforce-eager
VLLM_EXTRA_ARGS_2=--swap-space 24 --cpu-offload-gb 12 --enforce-eager
VLLM_EXTRA_ARGS_3=--swap-space 8
VLLM_EXTRA_ARGS_4=--swap-space 8
VLLM_EXTRA_ARGS_5=--swap-space 8
PORT_1=8101
PORT_2=8102
PORT_3=8103
PORT_4=8104
PORT_5=8105

# Optional
HF_HOME=~/.cache/huggingface
HUGGING_FACE_HUB_TOKEN=
